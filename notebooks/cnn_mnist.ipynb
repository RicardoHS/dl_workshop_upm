{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with CNNs\n",
    "This notebook introduces convolutional neural networks, widely employed for computer vision, using Keras. Their performance is demonstrated on the MNIST handwritten digit data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print( x_train.shape[0], 'train samples')\n",
    "print( x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_splits(X, y, ratio=0.1, cat=False):\n",
    "    \"\"\"\n",
    "    Finds a random split of size ratio*size(data).\n",
    "    Returns the corresponding splits of X and y.\n",
    "    \"\"\"\n",
    "    val_ids = np.random.choice(np.arange(X.shape[0]), int(X.shape[0]*ratio), replace=False)\n",
    "    train_ids = np.delete(np.arange(X.shape[0]), val_ids)\n",
    "    x_train = X[train_ids,:]\n",
    "    x_val = X[val_ids,:]\n",
    "    if cat:\n",
    "        y_train = y[train_ids,:]\n",
    "        y_val = y[val_ids,:]\n",
    "    else:\n",
    "        y_train = y[train_ids]\n",
    "        y_val = y[val_ids]                \n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (57000, 28, 28, 1). Validation: (3000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split apart validation set\n",
    "x_train, y_train, x_val, y_val = get_splits(x_train, y_train, ratio=0.05, cat=False)\n",
    "print( 'Train: {}. Validation: {}'.format(x_train.shape, x_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert labels to one-hot form\n",
    "num_classes=10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the CNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57000 samples, validate on 3000 samples\n",
      "Epoch 1/1\n",
      "57000/57000 [==============================] - 58s 1ms/step - loss: 0.2847 - acc: 0.9134 - val_loss: 0.0888 - val_acc: 0.9753\n",
      "Train on 57000 samples, validate on 3000 samples\n",
      "Epoch 1/1\n",
      "24960/57000 [============>.................] - ETA: 32s - loss: 0.1038 - acc: 0.9686"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-844b1dcbabb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 12\n",
    "\n",
    "for i in range(epochs):\n",
    "    history = model.fit(x_train, y_train, epochs=1, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val))\n",
    "    \n",
    "    train_loss.append(history.history['loss'])\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    \n",
    "    ax.clear()    \n",
    "    ax.plot(train_loss, color='red', label='Train')\n",
    "    ax.plot(val_loss, color='blue', label='Validation')\n",
    "\n",
    "    fig.canvas.draw()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict random digits from the test set\n",
    "import matplotlib.image as mpimg\n",
    "i = np.random.choice(np.arange(x_test.shape[1]))\n",
    "img_x = x_test[i].reshape([28,28])\n",
    "x = np.array([x_test[i]])\n",
    "print ('Prediction: {}'.format((np.argmax(model.predict(x)))))\n",
    "plt.imshow(img_x,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict our hand-written digits\n",
    "# Try it at home: draw a number on a 28x28 black background, using any Paint-like app. See if the model can guess it\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('number.png')\n",
    "x = np.array([img[:,:,[0]]])\n",
    "print ('Prediction: {}'.format((np.argmax(model.predict(x)))))\n",
    "plt.imshow(img,cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
