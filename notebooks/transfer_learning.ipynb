{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning for computer vision\n",
    "This notebook introduces the concept of transfer learning in computer vision. The problem of identifying objects in images is now considered to be mostly solved. This is due to several factors, among them the use of deep convolutional networks trained on large amounts of data. More strikingly, the intermediate layers learned by these networks can be used to solve new object recognition problems.\n",
    "\n",
    "Here we demonstrate how the weights of the convolutional layers learned by the VGG-16 network, trained on the ImageNet data set, can help us to quickly build a strikingly accurate image classifier using a moderately sized data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Load data\n",
    "#\n",
    "# This cell implements a function to load the Caltech 101 data set.\n",
    "# You can find it at http://www.vision.caltech.edu/Image_Datasets/Caltech101/\n",
    "# To simplify things a bit, I modified the images so that they all would be 224x224 in size\n",
    "# You can find the script I used for that in the scripts/ folder (pad_ct101.py)\n",
    "#################################################################\n",
    "from scipy import ndimage\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "CHANNELS = 3\n",
    "\n",
    "# In the paper describing the network we are going to use, \n",
    "# they say they preprocess the data by subtracting the ImageNet-wide mean\n",
    "IMAGENET_RGB_MEAN = [123.68, 116.779, 103.939]    \n",
    "\n",
    "def read_caltech101(mypath):\n",
    "    num_classes = 101\n",
    "\n",
    "    # We omit the BACKGROUND_Google class\n",
    "    dirs = [f for f in listdir(mypath) if f != 'BACKGROUND_Google']\n",
    "\n",
    "    label = 0\n",
    "    label_map = dict()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for dir in dirs:    \n",
    "        label_map[label] = dir\n",
    "        onlyfiles = [f for f in listdir(mypath+'/'+dir) if isfile(join(mypath+'/'+dir, f))]\n",
    "        for f in onlyfiles:\n",
    "            full_path = join(mypath+'/'+dir, f)\n",
    "            img = ndimage.imread(full_path).astype(np.float32)\n",
    "            # We only consider color images\n",
    "            if len(img.shape)==3:\n",
    "                #Preprocess according to VGG specs: subtract Imagenet RGB mean\n",
    "                for i in range(3):\n",
    "                    img[:,:,i] -= IMAGENET_RGB_MEAN[i]\n",
    "                X.append(img)\n",
    "                y.append(label)\n",
    "        label += 1\n",
    "\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.concatenate(X).reshape([len(X), WIDTH, HEIGHT, CHANNELS])    \n",
    "    y = np.array(y)\n",
    "    return X,y,label_map    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "X, y, label_map = read_caltech101('padded_101')\n",
    "\n",
    "# Transform labels to one-hot vectors\n",
    "num_classes = 101\n",
    "y_cat = keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "print 'X: {}. y: {}'.format(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in label_map:\n",
    "    print k, label_map[k], len(filter(lambda x: x==k, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the dataset\n",
    "i = np.random.randint(X.shape[0])\n",
    "x = np.copy(X[i])\n",
    "for j in range(3):\n",
    "    x[:,:,j] += IMAGENET_RGB_MEAN[j]\n",
    "x=x/255.\n",
    "print i,label_map[y[i]]\n",
    "plt.imshow(x, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Baseline tests:\n",
    "# We will try out a relatively simple task. We'll only consider\n",
    "# four classes: Airplane, motorbike, faces, leopard (the most numerous in Caltech 101)\n",
    "# We'll train a couple of well-known classifiers to see how well we can do\n",
    "# with a straightforward approach\n",
    "#\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter the dataset so it only contains the two considered classes\n",
    "# Warning! Make sure these indices correspond to the classes mentioned above. Check the dictionary object\n",
    "classes = [0,2,3,5]\n",
    "filtered_ids = filter(lambda i: y[i] in classes, np.arange(X.shape[0]))\n",
    "X_filt = X[filtered_ids,:]\n",
    "y_filt = y[filtered_ids]\n",
    "len(filtered_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_splits(X, y, ratio=0.1, cat=False):\n",
    "    \"\"\"\n",
    "    Finds a random split of size ratio*size(data).\n",
    "    Returns the corresponding splits of X and y.\n",
    "    \"\"\"\n",
    "    val_ids = np.random.choice(np.arange(X.shape[0]), int(X.shape[0]*ratio), replace=False)\n",
    "    train_ids = np.delete(np.arange(X.shape[0]), val_ids)\n",
    "    x_train = X[train_ids,:]\n",
    "    x_val = X[val_ids,:]\n",
    "    if cat:\n",
    "        y_train = y[train_ids,:]\n",
    "        y_val = y[val_ids,:]\n",
    "    else:\n",
    "        y_train = y[train_ids]\n",
    "        y_val = y[val_ids]                \n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def eval(y, preds, classes):\n",
    "    \"\"\"\n",
    "    Given a set of labels y and predictions preds, computes precision, recall and F1.\n",
    "    \"\"\"\n",
    "    for i in classes:\n",
    "        preds_i = [1 if j==i else 0 for j in preds]\n",
    "        y_i = [1 if j==i else 0 for j in y]\n",
    "        print 'Class {}:'.format(label_map[i])    \n",
    "        print 'Precision: {}'.format(metrics.precision_score(y_i, preds_i))\n",
    "        print 'Recall: {}'.format(metrics.recall_score(y_i, preds_i))\n",
    "        print 'F1: {}'.format(metrics.f1_score(y_i, preds_i))\n",
    "        print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Baseline tests: First, we will train a couple of well-known classifiers\n",
    "# to see how a basic approach does\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtain train/test splits\n",
    "x_train, y_train, x_test, y_test = get_splits(X_filt, y_filt, ratio=0.1, cat=False)\n",
    "print 'Train: {}. Test: {}'.format(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#====================\n",
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', class_weight='balanced')\n",
    "\n",
    "#Convert the images into 1-D vectors\n",
    "x_train_shaped = x_train.reshape([x_train.shape[0], WIDTH*HEIGHT*CHANNELS])\n",
    "clf.fit(x_train_shaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#====================\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=10)\n",
    "\n",
    "#Convert the images into 1-D vectors\n",
    "x_train_shaped = x_train.reshape([x_train.shape[0], WIDTH*HEIGHT*CHANNELS])\n",
    "clf.fit(x_train_shaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the trained classifer\n",
    "classes = np.unique(y_train)\n",
    "print classes\n",
    "x_train_shaped = x_train.reshape([x_train.shape[0], WIDTH*HEIGHT*CHANNELS])\n",
    "preds = clf.predict(x_train_shaped)\n",
    "print '='*50\n",
    "print 'Train results:'\n",
    "eval(y_train, preds, classes)\n",
    "x_test_shaped = x_test.reshape([x_test.shape[0], WIDTH*HEIGHT*CHANNELS])\n",
    "preds = clf.predict(x_test_shaped)\n",
    "print '='*50\n",
    "print 'Test results:'\n",
    "eval(y_test, preds, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sanity check: predict random digits from the train/test set\n",
    "# This way we can check visually if our classifier is well trained\n",
    "import matplotlib.image as mpimg\n",
    "check_set = x_test\n",
    "check_y = y_test\n",
    "\n",
    "i = np.random.choice(np.arange(check_set.shape[0]))\n",
    "print i\n",
    "img = np.copy(check_set[i])\n",
    "x = np.copy(img.reshape([1, 224*224*3]))\n",
    "for j in range(3):\n",
    "    img[:,:,j] += IMAGENET_RGB_MEAN[j]\n",
    "print 'Prediction: {}. Confidence: {}'.format(label_map[int(clf.predict(x))], np.max(clf.predict_proba(x)))\n",
    "print 'Label: {}'.format(label_map[check_y[i]])\n",
    "img /= 255.\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import test images\n",
    "# Here we load a bunch of images we got off the Internet (stored in test_imgs), \n",
    "# to see how well our classifier does in the wild.\n",
    "# These were images I downloaded and saved in a local directory, so you'll have to do that yourself.\n",
    "# If you want to, download a bunch of (preferrably square) images from the net and scale them to 224x224\n",
    "# Notice that reusing convolutional nets is not so restrictive, as the convolutional filters can be applied to any\n",
    "# input size.\n",
    "# Remember the test I did: I took screenshots from youtube videos and fed them to the classifier. That way I could be\n",
    "# sure that neither my classifier nor the VGG16 net had ever seen those, so no trick.\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "dir = 'test_imgs'\n",
    "test_imgs = [join(dir,f) for f in listdir('test_imgs') if isfile(join(dir,f)) and '.jpg' in f]\n",
    "print test_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict images taken from the internet\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread(test_imgs[i])\n",
    "i+=1\n",
    "x = np.array([img]).astype(np.float32)\n",
    "for j in range(3):\n",
    "    x[0,:,:,j] -= IMAGENET_RGB_MEAN[j]\n",
    "x=x.reshape([1, 224*224*3])\n",
    "print 'Prediction: {}. Confidence: {}'.format(label_map[int(clf.predict(x))], np.max(clf.predict_proba(x)))\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Transfer learning\n",
    "# We now adopt an alternative approach. We will take a very deep network trained on ImageNet\n",
    "# (a data set of about 14M images) and remove the uppermost layers (the classifier). We will\n",
    "# then train a classifier of our own.\n",
    "#\n",
    "# Take into account that if we take all the classes in Caltech 101, the classifier will not be as accurate.\n",
    "# Some classes are not numerous enough and there is a considerable amount of variability to correctly learn 101 of them.\n",
    "# However, remember we only tried a logistic regression model in the course. You can also stack a dense neural network\n",
    "# on top of VGG-16. Perhaps you can do better with that approach in the full 101-class data set.\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load VGG-16 trained on ImageNet\n",
    "# Look at the arguments: \n",
    "# - we don't include the top of the network (i.e. we remove the classifier). We just want to \n",
    "# keep the feature extractors learned in the hidden layers. \n",
    "# - We also choose the imagenet weights, because we want to benefit from what was learned by the authors\n",
    "#\n",
    "# More info:\n",
    "# - https://keras.io/applications/#vgg16\n",
    "# - https://arxiv.org/pdf/1409.1556.pdf\n",
    "from  keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "num_classes=4\n",
    "pt_model = applications.vgg16.VGG16(include_top=False, \n",
    "                                        weights='imagenet', \n",
    "                                        input_shape=(224,224,3), \n",
    "                                        pooling=None, \n",
    "                                        classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the network architecture\n",
    "# Notice how big the network is (and we removed the classifier on top, which is by far the most complex part)\n",
    "# For some reason not yet fully understood, deep neural networks can estimate millions of parameters \"correctly\"\n",
    "# if they have enough data\n",
    "pt_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert to Sequential (because it's what we've seen in the course, \n",
    "# but the functional API is more convenient for this purpose)\n",
    "model = Sequential()\n",
    "for l in pt_model.layers:\n",
    "    model.add(l)\n",
    "model.set_weights(pt_model.get_weights())\n",
    "\n",
    "# We add a flattening layer in order to train a classifier on the top\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform training and validation sets to feature space (the representation learned by the pretrained net)\n",
    "print 'Predicting train'\n",
    "x_train_rep = model.predict(x_train, verbose=1)\n",
    "print 'Predicting validation'\n",
    "x_test_rep = model.predict(x_test, verbose=1)\n",
    "print x_train_rep.shape, x_test_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Train a logistic regression model on feature space\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "x_train_shaped = np.array(x_train_rep).reshape([x_train_rep.shape[0], 7*7*512])\n",
    "clf.fit(x_train_shaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "print classes\n",
    "preds = clf.predict(x_train_shaped)\n",
    "print 'Train results:'\n",
    "eval(y_train, preds, classes)\n",
    "x_test_shaped = x_test_rep.reshape([x_test_rep.shape[0], 7*7*512])\n",
    "preds = clf.predict(x_test_shaped)\n",
    "print 'Test results:'\n",
    "eval(y_test, preds, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict random images with logistic regression on feature space\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread(test_imgs[i])\n",
    "i+=1\n",
    "x = np.array([img]).astype(np.float32)\n",
    "for j in range(3):\n",
    "    x[0,:,:,j] -= IMAGENET_RGB_MEAN[j]\n",
    "x=model.predict(x).reshape([1, 7*7*512])\n",
    "prediction = np.argmax(clf.predict(x))\n",
    "\n",
    "print 'Prediction: {}. Confidence: {}'.format(label_map[int(clf.predict(x))], np.max(clf.predict_proba(x)))\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also train a deep neural network on top of the VGG-16 features. In fact, for more complex tasks, that\n",
    "can be much better than a simple logistic regression classifier.\n",
    "\n",
    "There are various ways we can do this. We can place the classifier on top of the VGG network and freeze the VGG layes (see Keras API). Alternatively, we can train the classifier on the transformed inputs and then stacked the resulting (trained) network on top of VGG. This way we make the transformation+classification in one step (model.predict(x))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Classifier on top of VGG-16\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "input_shape = [7*7*512,]\n",
    "num_classes = 101\n",
    "\n",
    "clf = Sequential()\n",
    "clf.add(Dense(256, input_shape=input_shape, activation='relu'))\n",
    "clf.add(Dropout(0.25))\n",
    "clf.add(Dense(64, activation='relu'))\n",
    "clf.add(Dropout(0.5))\n",
    "clf.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Classifier on top of VGG-16\n",
    "\n",
    "input_shape = [7*7*512,]\n",
    "num_classes = 101\n",
    "\n",
    "clf = Sequential()\n",
    "clf.add(Dense(256, input_shape=input_shape, activation='relu'))\n",
    "clf.add(Dropout(0.25))\n",
    "clf.add(Dense(128, activation='relu'))\n",
    "clf.add(Dropout(0.25))\n",
    "clf.add(Dense(64, activation='relu'))\n",
    "clf.add(Dropout(0.25))\n",
    "clf.add(Dense(64, activation='relu'))\n",
    "clf.add(Dropout(0.5))\n",
    "clf.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remember: the last layer is softmax, so we need to transform the labels into one-hot vectors\n",
    "y_train_cat = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train and monitor progress\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "\n",
    "x_train_shaped = x_train_rep.reshape([x_train_rep.shape[0],7*7*512])\n",
    "x_test_shaped = x_test_rep.reshape([x_test_rep.shape[0],7*7*512])\n",
    "                                     \n",
    "for i in range(50):\n",
    "    print i\n",
    "    history = clf.fit(x_train_shaped, y_train_cat, epochs=1, batch_size=128, verbose=1, validation_data=(x_test_shaped, y_test_cat))\n",
    "    \n",
    "    train_loss.append(history.history['loss'])\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    \n",
    "    ax.clear()    \n",
    "    ax.plot(train_loss, color='red', label='Train')\n",
    "    ax.plot(val_loss, color='blue', label='Validation')\n",
    "\n",
    "    fig.canvas.draw()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('vgg_clf.h5')\n",
    "model.save_weights('vgg_clf_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
